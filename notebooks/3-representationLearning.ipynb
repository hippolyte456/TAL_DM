{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP & representation learning : Neural Embeddings, Text Classification, Text Generation\n",
    "\n",
    "\n",
    "To use statistical classifiers with text, it is first necessary to vectorize the text. In the first practical session we explored the **bag of word** model. \n",
    "\n",
    "Modern **state of the art** methods uses  embeddings to vectorize the text before classification in order to avoid feature engineering.\n",
    "\n",
    "## Dataset\n",
    "https://github.com/vguigue/tuto_TAL/tree/main/notebooks/ressources\n",
    "\n",
    "## \"Modern\" NLP pipeline\n",
    "\n",
    "By opposition to the **bag of word** model, in the modern NLP pipeline everything is **embeddings**. Instead of encoding a text as a **sparse vector** of length $D$ (size of feature dictionnary) the goal is to encode the text in a meaningful dense vector of a small size $|e| <<< |D|$. \n",
    "\n",
    "\n",
    "The raw classification pipeline is then the following:\n",
    "\n",
    "```\n",
    "raw text ---|embedding table|-->  vectors --|Neural Net|--> class \n",
    "```\n",
    "\n",
    "\n",
    "### Using a  language model:\n",
    "\n",
    "How to tokenize the text and extract a feature dictionnary is still a manual task. To directly have meaningful embeddings, it is common to use a pre-trained language model such as `word2vec` which we explore in this practical.\n",
    "\n",
    "In this setting, the pipeline becomes the following:\n",
    "```\n",
    "      \n",
    "raw text ---|(pre-trained) Language Model|--> vectors --|classifier (or fine-tuning)|--> class \n",
    "```\n",
    "\n",
    "\n",
    "- #### Classic word embeddings\n",
    "\n",
    " - [Word2Vec](https://arxiv.org/abs/1301.3781)\n",
    " - [Glove](https://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "\n",
    "- #### bleeding edge language models techniques (only here for reference)\n",
    "\n",
    " - [UMLFIT](https://arxiv.org/abs/1801.06146)\n",
    " - [ELMO](https://arxiv.org/abs/1802.05365)\n",
    " - [GPT](https://blog.openai.com/language-unsupervised/)\n",
    " - [BERT](https://arxiv.org/abs/1810.04805)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Goal of this session:\n",
    "\n",
    "1. Train word embeddings on training dataset\n",
    "2. Tinker with the learnt embeddings and see learnt relations\n",
    "3. Tinker with pre-trained embeddings.\n",
    "4. Use those embeddings for classification\n",
    "5. Compare different embedding models\n",
    "6. Pytorch first look: learn to generate text.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##  Loading data (same as in nlp 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train reviews :  25000\n",
      "----> # of positive :  12500\n",
      "----> # of negative :  12500\n",
      "\n",
      "[\"The undoubted highlight of this movie is Peter O'Toole's performance. In turn wildly comical and terribly terribly tragic. Does anybody do it better than O'Toole? I don't think so. What a great face that man has!<br /><br />The story is an odd one and quite disturbing and emotionally intense in parts (especially toward the end) but it is also oddly touching and does succeed on many levels. However, I felt the film basically revolved around Peter O'Toole's luminous performance and I'm sure I wouldn't have enjoyed it even half as much if he hadn't been in it.\", 1]\n",
      "\n",
      "Number of test reviews :  25000\n",
      "----> # of positive :  12500\n",
      "----> # of negative :  12500\n",
      "\n",
      "['Although credit should have been given to Dr. Seuess for stealing the story-line of \"Horton Hatches The Egg\", this was a fine film. It touched both the emotions and the intellect. Due especially to the incredible performance of seven year old Justin Henry and a script that was sympathetic to each character (and each one\\'s predicament), the thought provoking elements linger long after the tear jerking ones are over. Overall, superior acting from a solid cast, excellent directing, and a very powerful script. The right touches of humor throughout help keep a \"heavy\" subject from becoming tedious or difficult to sit through. Lastly, this film stands the test of time and seems in no way dated, decades after it was released.', 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "#### /!\\ YOU NEED TO UNZIP dataset/json_pol.zip first /!\\\n",
    "\n",
    "\n",
    "# Loading json\n",
    "with open(\"ressources/json_pol\",encoding=\"utf-8\") as f:\n",
    "    data = f.readlines()\n",
    "    json_data = json.loads(data[0])\n",
    "    train = json_data[\"train\"]\n",
    "    test = json_data[\"test\"]\n",
    "    \n",
    "\n",
    "# Quick Check\n",
    "counter_train = Counter((x[1] for x in train))\n",
    "counter_test = Counter((x[1] for x in test))\n",
    "print(\"Number of train reviews : \", len(train))\n",
    "print(\"----> # of positive : \", counter_train[1])\n",
    "print(\"----> # of negative : \", counter_train[0])\n",
    "print(\"\")\n",
    "print(train[0])\n",
    "print(\"\")\n",
    "print(\"Number of test reviews : \",len(test))\n",
    "print(\"----> # of positive : \", counter_test[1])\n",
    "print(\"----> # of negative : \", counter_test[0])\n",
    "\n",
    "print(\"\")\n",
    "print(test[0])\n",
    "print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec: Quick Recap\n",
    "\n",
    "**[Word2Vec](https://arxiv.org/abs/1301.3781) is composed of two distinct language models (CBOW and SG), optimized to quickly learn word vectors**\n",
    "\n",
    "\n",
    "given a random text: `i'm taking the dog out for a walk`\n",
    "\n",
    "\n",
    "\n",
    "### (a) Continuous Bag of Word (CBOW)\n",
    "    -  predicts a word given a context\n",
    "    \n",
    "maximizing `p(dog | i'm taking the ___ out for a walk)`\n",
    "    \n",
    "### (b) Skip-Gram (SG)               \n",
    "    -  predicts a context given a word\n",
    "    \n",
    " maximizing `p(i'm taking the out for a walk | dog)`\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: train (or load) a language model (word2vec)\n",
    "\n",
    "Gensim has one of [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html) fastest implementation.\n",
    "\n",
    "\n",
    "### Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if gensim not installed yet\n",
    "# ! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 16:29:54,391 : INFO : collecting all words and their counts\n",
      "2022-11-30 16:29:54,392 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-11-30 16:29:55,483 : INFO : PROGRESS: at sentence #10000, processed 2358544 words, keeping 155393 word types\n",
      "2022-11-30 16:29:56,559 : INFO : PROGRESS: at sentence #20000, processed 4675912 words, keeping 243050 word types\n",
      "2022-11-30 16:29:57,080 : INFO : collected 280617 word types from a corpus of 5844680 raw words and 25000 sentences\n",
      "2022-11-30 16:29:57,081 : INFO : Creating a fresh vocabulary\n",
      "2022-11-30 16:29:57,570 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 49345 unique words (17.584465659600095%% of original 280617, drops 231272)', 'datetime': '2022-11-30T16:29:57.570347', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 06:56:58) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.0-53-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2022-11-30 16:29:57,571 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 5517507 word corpus (94.40220850414394%% of original 5844680, drops 327173)', 'datetime': '2022-11-30T16:29:57.571513', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 06:56:58) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.0-53-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2022-11-30 16:29:58,051 : INFO : deleting the raw counts dictionary of 280617 items\n",
      "2022-11-30 16:29:58,070 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2022-11-30 16:29:58,071 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 4268608.194985565 word corpus (77.4%% of prior 5517507)', 'datetime': '2022-11-30T16:29:58.071642', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 06:56:58) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.0-53-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2022-11-30 16:29:59,389 : INFO : estimated required memory for 49345 words and 100 dimensions: 64148500 bytes\n",
      "2022-11-30 16:29:59,395 : INFO : resetting layer weights\n",
      "2022-11-30 16:29:59,496 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-11-30T16:29:59.496655', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 06:56:58) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.0-53-generic-x86_64-with-glibc2.35', 'event': 'build_vocab'}\n",
      "2022-11-30 16:29:59,508 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 49345 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-11-30T16:29:59.508813', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 06:56:58) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.0-53-generic-x86_64-with-glibc2.35', 'event': 'train'}\n",
      "2022-11-30 16:30:00,577 : INFO : EPOCH 1 - PROGRESS: at 2.23% examples, 94176 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:01,630 : INFO : EPOCH 1 - PROGRESS: at 5.24% examples, 108231 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:02,642 : INFO : EPOCH 1 - PROGRESS: at 7.46% examples, 105002 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:03,686 : INFO : EPOCH 1 - PROGRESS: at 10.01% examples, 104420 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:04,762 : INFO : EPOCH 1 - PROGRESS: at 12.87% examples, 106141 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:05,770 : INFO : EPOCH 1 - PROGRESS: at 16.11% examples, 110811 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:06,776 : INFO : EPOCH 1 - PROGRESS: at 19.10% examples, 113124 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:07,846 : INFO : EPOCH 1 - PROGRESS: at 22.28% examples, 114813 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:08,896 : INFO : EPOCH 1 - PROGRESS: at 25.16% examples, 115044 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:09,904 : INFO : EPOCH 1 - PROGRESS: at 28.06% examples, 116279 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:10,936 : INFO : EPOCH 1 - PROGRESS: at 31.30% examples, 117669 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:11,957 : INFO : EPOCH 1 - PROGRESS: at 34.12% examples, 118300 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:13,020 : INFO : EPOCH 1 - PROGRESS: at 37.20% examples, 118577 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:14,076 : INFO : EPOCH 1 - PROGRESS: at 40.53% examples, 119352 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:15,104 : INFO : EPOCH 1 - PROGRESS: at 43.48% examples, 119741 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:16,140 : INFO : EPOCH 1 - PROGRESS: at 46.38% examples, 120060 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:17,194 : INFO : EPOCH 1 - PROGRESS: at 49.70% examples, 121010 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:18,312 : INFO : EPOCH 1 - PROGRESS: at 52.94% examples, 121083 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:19,325 : INFO : EPOCH 1 - PROGRESS: at 56.18% examples, 121744 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:20,333 : INFO : EPOCH 1 - PROGRESS: at 59.24% examples, 122090 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:21,334 : INFO : EPOCH 1 - PROGRESS: at 62.10% examples, 122360 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:22,360 : INFO : EPOCH 1 - PROGRESS: at 65.26% examples, 122516 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:23,459 : INFO : EPOCH 1 - PROGRESS: at 68.54% examples, 122628 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:24,527 : INFO : EPOCH 1 - PROGRESS: at 71.75% examples, 122603 words/s, in_qsize 3, out_qsize 2\n",
      "2022-11-30 16:30:25,531 : INFO : EPOCH 1 - PROGRESS: at 74.98% examples, 123125 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:26,545 : INFO : EPOCH 1 - PROGRESS: at 78.10% examples, 123338 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:27,557 : INFO : EPOCH 1 - PROGRESS: at 81.22% examples, 123543 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-30 16:30:28,579 : INFO : EPOCH 1 - PROGRESS: at 84.35% examples, 123949 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:29,697 : INFO : EPOCH 1 - PROGRESS: at 87.56% examples, 123909 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:30,723 : INFO : EPOCH 1 - PROGRESS: at 90.54% examples, 123991 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:31,754 : INFO : EPOCH 1 - PROGRESS: at 93.92% examples, 124517 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:32,883 : INFO : EPOCH 1 - PROGRESS: at 97.12% examples, 124422 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:33,648 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-11-30 16:30:33,663 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-11-30 16:30:33,733 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-11-30 16:30:33,734 : INFO : EPOCH - 1 : training on 5844680 raw words (4269413 effective words) took 34.2s, 124779 effective words/s\n",
      "2022-11-30 16:30:34,753 : INFO : EPOCH 2 - PROGRESS: at 2.70% examples, 119464 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:35,769 : INFO : EPOCH 2 - PROGRESS: at 5.89% examples, 126776 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:36,814 : INFO : EPOCH 2 - PROGRESS: at 8.98% examples, 127617 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:37,907 : INFO : EPOCH 2 - PROGRESS: at 12.18% examples, 126947 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-30 16:30:38,913 : INFO : EPOCH 2 - PROGRESS: at 15.20% examples, 127065 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:39,917 : INFO : EPOCH 2 - PROGRESS: at 18.43% examples, 128371 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:40,936 : INFO : EPOCH 2 - PROGRESS: at 21.60% examples, 129014 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:41,940 : INFO : EPOCH 2 - PROGRESS: at 24.69% examples, 128990 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:43,051 : INFO : EPOCH 2 - PROGRESS: at 27.58% examples, 127455 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:44,125 : INFO : EPOCH 2 - PROGRESS: at 30.79% examples, 127385 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:45,155 : INFO : EPOCH 2 - PROGRESS: at 33.97% examples, 128335 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:46,192 : INFO : EPOCH 2 - PROGRESS: at 37.20% examples, 128612 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:47,213 : INFO : EPOCH 2 - PROGRESS: at 40.34% examples, 128473 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:48,223 : INFO : EPOCH 2 - PROGRESS: at 42.98% examples, 127384 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:49,308 : INFO : EPOCH 2 - PROGRESS: at 45.58% examples, 125877 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:50,408 : INFO : EPOCH 2 - PROGRESS: at 48.35% examples, 124861 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-30 16:30:51,424 : INFO : EPOCH 2 - PROGRESS: at 51.32% examples, 125047 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:52,462 : INFO : EPOCH 2 - PROGRESS: at 54.75% examples, 125720 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:53,500 : INFO : EPOCH 2 - PROGRESS: at 57.88% examples, 125653 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:54,511 : INFO : EPOCH 2 - PROGRESS: at 60.94% examples, 126078 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:55,613 : INFO : EPOCH 2 - PROGRESS: at 64.30% examples, 126290 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:56,656 : INFO : EPOCH 2 - PROGRESS: at 67.87% examples, 126851 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:57,670 : INFO : EPOCH 2 - PROGRESS: at 71.23% examples, 127208 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:30:58,712 : INFO : EPOCH 2 - PROGRESS: at 74.30% examples, 127085 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:30:59,718 : INFO : EPOCH 2 - PROGRESS: at 77.54% examples, 127477 words/s, in_qsize 4, out_qsize 0\n",
      "2022-11-30 16:31:00,771 : INFO : EPOCH 2 - PROGRESS: at 80.91% examples, 127608 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:01,900 : INFO : EPOCH 2 - PROGRESS: at 84.01% examples, 127399 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-30 16:31:03,038 : INFO : EPOCH 2 - PROGRESS: at 87.48% examples, 127621 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:04,057 : INFO : EPOCH 2 - PROGRESS: at 90.68% examples, 127860 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:05,130 : INFO : EPOCH 2 - PROGRESS: at 93.92% examples, 127867 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:06,130 : INFO : EPOCH 2 - PROGRESS: at 97.12% examples, 128149 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:06,945 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-11-30 16:31:06,976 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-11-30 16:31:07,011 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-11-30 16:31:07,012 : INFO : EPOCH - 2 : training on 5844680 raw words (4269397 effective words) took 33.3s, 128314 effective words/s\n",
      "2022-11-30 16:31:08,018 : INFO : EPOCH 3 - PROGRESS: at 2.70% examples, 120747 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:09,092 : INFO : EPOCH 3 - PROGRESS: at 6.04% examples, 127417 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:10,116 : INFO : EPOCH 3 - PROGRESS: at 9.16% examples, 128899 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:11,208 : INFO : EPOCH 3 - PROGRESS: at 12.18% examples, 126097 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:12,235 : INFO : EPOCH 3 - PROGRESS: at 15.04% examples, 124529 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:13,305 : INFO : EPOCH 3 - PROGRESS: at 18.43% examples, 126071 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:14,388 : INFO : EPOCH 3 - PROGRESS: at 21.60% examples, 125864 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-30 16:31:15,438 : INFO : EPOCH 3 - PROGRESS: at 25.16% examples, 128074 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:16,520 : INFO : EPOCH 3 - PROGRESS: at 28.20% examples, 127806 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:17,582 : INFO : EPOCH 3 - PROGRESS: at 31.57% examples, 128459 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:18,629 : INFO : EPOCH 3 - PROGRESS: at 34.64% examples, 128537 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:19,661 : INFO : EPOCH 3 - PROGRESS: at 37.89% examples, 128838 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:20,692 : INFO : EPOCH 3 - PROGRESS: at 41.10% examples, 128585 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:21,719 : INFO : EPOCH 3 - PROGRESS: at 44.00% examples, 128356 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:22,747 : INFO : EPOCH 3 - PROGRESS: at 46.72% examples, 127737 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:23,750 : INFO : EPOCH 3 - PROGRESS: at 49.34% examples, 126916 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:24,844 : INFO : EPOCH 3 - PROGRESS: at 52.34% examples, 126408 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:25,856 : INFO : EPOCH 3 - PROGRESS: at 55.65% examples, 126799 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:26,858 : INFO : EPOCH 3 - PROGRESS: at 58.38% examples, 126202 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:27,877 : INFO : EPOCH 3 - PROGRESS: at 61.41% examples, 126525 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:28,889 : INFO : EPOCH 3 - PROGRESS: at 64.68% examples, 126907 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:29,896 : INFO : EPOCH 3 - PROGRESS: at 68.04% examples, 127327 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:30,949 : INFO : EPOCH 3 - PROGRESS: at 71.23% examples, 127156 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:31,965 : INFO : EPOCH 3 - PROGRESS: at 74.30% examples, 127165 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:33,013 : INFO : EPOCH 3 - PROGRESS: at 77.38% examples, 127072 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:34,100 : INFO : EPOCH 3 - PROGRESS: at 80.72% examples, 127062 words/s, in_qsize 4, out_qsize 1\n",
      "2022-11-30 16:31:35,118 : INFO : EPOCH 3 - PROGRESS: at 84.01% examples, 127624 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:36,214 : INFO : EPOCH 3 - PROGRESS: at 87.20% examples, 127532 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:37,309 : INFO : EPOCH 3 - PROGRESS: at 90.54% examples, 127684 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:38,370 : INFO : EPOCH 3 - PROGRESS: at 93.77% examples, 127742 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:39,377 : INFO : EPOCH 3 - PROGRESS: at 96.76% examples, 127784 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:40,369 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-11-30 16:31:40,371 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-11-30 16:31:40,448 : INFO : EPOCH 3 - PROGRESS: at 100.00% examples, 127666 words/s, in_qsize 0, out_qsize 1\n",
      "2022-11-30 16:31:40,450 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-11-30 16:31:40,451 : INFO : EPOCH - 3 : training on 5844680 raw words (4268047 effective words) took 33.4s, 127654 effective words/s\n",
      "2022-11-30 16:31:41,551 : INFO : EPOCH 4 - PROGRESS: at 2.84% examples, 118065 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:42,575 : INFO : EPOCH 4 - PROGRESS: at 5.89% examples, 122022 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:43,578 : INFO : EPOCH 4 - PROGRESS: at 8.98% examples, 126099 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:44,649 : INFO : EPOCH 4 - PROGRESS: at 11.90% examples, 122946 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:45,675 : INFO : EPOCH 4 - PROGRESS: at 15.04% examples, 124790 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-30 16:31:46,695 : INFO : EPOCH 4 - PROGRESS: at 18.27% examples, 126140 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:47,727 : INFO : EPOCH 4 - PROGRESS: at 21.42% examples, 126815 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:48,750 : INFO : EPOCH 4 - PROGRESS: at 24.50% examples, 126772 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:49,770 : INFO : EPOCH 4 - PROGRESS: at 26.90% examples, 124436 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:50,823 : INFO : EPOCH 4 - PROGRESS: at 29.21% examples, 121493 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:51,827 : INFO : EPOCH 4 - PROGRESS: at 31.59% examples, 119514 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:52,975 : INFO : EPOCH 4 - PROGRESS: at 34.28% examples, 118241 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:54,015 : INFO : EPOCH 4 - PROGRESS: at 37.20% examples, 118160 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:55,047 : INFO : EPOCH 4 - PROGRESS: at 39.62% examples, 116676 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:56,075 : INFO : EPOCH 4 - PROGRESS: at 42.35% examples, 116339 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:57,166 : INFO : EPOCH 4 - PROGRESS: at 44.76% examples, 115176 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:31:58,170 : INFO : EPOCH 4 - PROGRESS: at 47.05% examples, 114293 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:31:59,182 : INFO : EPOCH 4 - PROGRESS: at 50.18% examples, 115404 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:32:00,271 : INFO : EPOCH 4 - PROGRESS: at 53.42% examples, 115939 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:01,271 : INFO : EPOCH 4 - PROGRESS: at 56.86% examples, 117206 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:02,297 : INFO : EPOCH 4 - PROGRESS: at 60.06% examples, 117977 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:03,333 : INFO : EPOCH 4 - PROGRESS: at 63.41% examples, 119165 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:04,429 : INFO : EPOCH 4 - PROGRESS: at 66.85% examples, 119439 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:05,489 : INFO : EPOCH 4 - PROGRESS: at 70.34% examples, 120146 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:06,514 : INFO : EPOCH 4 - PROGRESS: at 73.61% examples, 120684 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-30 16:32:07,603 : INFO : EPOCH 4 - PROGRESS: at 76.83% examples, 120901 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:08,629 : INFO : EPOCH 4 - PROGRESS: at 80.39% examples, 121639 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:09,694 : INFO : EPOCH 4 - PROGRESS: at 83.52% examples, 121928 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:10,716 : INFO : EPOCH 4 - PROGRESS: at 86.84% examples, 122571 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:32:11,724 : INFO : EPOCH 4 - PROGRESS: at 90.06% examples, 123005 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:32:12,724 : INFO : EPOCH 4 - PROGRESS: at 93.38% examples, 123680 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:13,759 : INFO : EPOCH 4 - PROGRESS: at 96.76% examples, 124170 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:14,629 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-11-30 16:32:14,648 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-11-30 16:32:14,678 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-11-30 16:32:14,679 : INFO : EPOCH - 4 : training on 5844680 raw words (4267081 effective words) took 34.2s, 124711 effective words/s\n",
      "2022-11-30 16:32:15,734 : INFO : EPOCH 5 - PROGRESS: at 2.56% examples, 108315 words/s, in_qsize 6, out_qsize 1\n",
      "2022-11-30 16:32:16,742 : INFO : EPOCH 5 - PROGRESS: at 5.24% examples, 111027 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:17,810 : INFO : EPOCH 5 - PROGRESS: at 7.62% examples, 107131 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:18,818 : INFO : EPOCH 5 - PROGRESS: at 10.17% examples, 107050 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:32:19,877 : INFO : EPOCH 5 - PROGRESS: at 12.74% examples, 105880 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:32:20,920 : INFO : EPOCH 5 - PROGRESS: at 15.40% examples, 106544 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:21,946 : INFO : EPOCH 5 - PROGRESS: at 18.27% examples, 108175 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:22,949 : INFO : EPOCH 5 - PROGRESS: at 21.42% examples, 111407 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:32:23,960 : INFO : EPOCH 5 - PROGRESS: at 24.87% examples, 114773 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:25,023 : INFO : EPOCH 5 - PROGRESS: at 27.92% examples, 116136 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:26,144 : INFO : EPOCH 5 - PROGRESS: at 31.46% examples, 117883 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:27,166 : INFO : EPOCH 5 - PROGRESS: at 34.64% examples, 119618 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:28,177 : INFO : EPOCH 5 - PROGRESS: at 37.89% examples, 120775 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:29,185 : INFO : EPOCH 5 - PROGRESS: at 40.18% examples, 118835 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:30,265 : INFO : EPOCH 5 - PROGRESS: at 42.49% examples, 117009 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:31,371 : INFO : EPOCH 5 - PROGRESS: at 45.39% examples, 116985 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:32,390 : INFO : EPOCH 5 - PROGRESS: at 48.04% examples, 116707 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:33,424 : INFO : EPOCH 5 - PROGRESS: at 50.69% examples, 116444 words/s, in_qsize 4, out_qsize 1\n",
      "2022-11-30 16:32:34,426 : INFO : EPOCH 5 - PROGRESS: at 53.71% examples, 117032 words/s, in_qsize 4, out_qsize 1\n",
      "2022-11-30 16:32:35,450 : INFO : EPOCH 5 - PROGRESS: at 56.86% examples, 117463 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:32:36,469 : INFO : EPOCH 5 - PROGRESS: at 60.05% examples, 118266 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:37,478 : INFO : EPOCH 5 - PROGRESS: at 62.87% examples, 118670 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:38,508 : INFO : EPOCH 5 - PROGRESS: at 66.28% examples, 119278 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:39,552 : INFO : EPOCH 5 - PROGRESS: at 69.30% examples, 119208 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:40,578 : INFO : EPOCH 5 - PROGRESS: at 72.46% examples, 119500 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:41,627 : INFO : EPOCH 5 - PROGRESS: at 75.64% examples, 119947 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:32:42,652 : INFO : EPOCH 5 - PROGRESS: at 78.44% examples, 119696 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:43,685 : INFO : EPOCH 5 - PROGRESS: at 81.60% examples, 119940 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:32:44,717 : INFO : EPOCH 5 - PROGRESS: at 84.50% examples, 120169 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:45,734 : INFO : EPOCH 5 - PROGRESS: at 87.68% examples, 120648 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:46,738 : INFO : EPOCH 5 - PROGRESS: at 90.68% examples, 120921 words/s, in_qsize 6, out_qsize 0\n",
      "2022-11-30 16:32:47,765 : INFO : EPOCH 5 - PROGRESS: at 93.92% examples, 121324 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:48,846 : INFO : EPOCH 5 - PROGRESS: at 97.13% examples, 121508 words/s, in_qsize 5, out_qsize 0\n",
      "2022-11-30 16:32:49,599 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-11-30 16:32:49,681 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-11-30 16:32:49,682 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-11-30 16:32:49,685 : INFO : EPOCH - 5 : training on 5844680 raw words (4269251 effective words) took 35.0s, 121971 effective words/s\n",
      "2022-11-30 16:32:49,686 : INFO : Word2Vec lifecycle event {'msg': 'training on 29223400 raw words (21343189 effective words) took 170.2s, 125420 effective words/s', 'datetime': '2022-11-30T16:32:49.686774', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 06:56:58) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.0-53-generic-x86_64-with-glibc2.35', 'event': 'train'}\n",
      "2022-11-30 16:32:49,689 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=49345, vector_size=100, alpha=0.025)', 'datetime': '2022-11-30T16:32:49.689497', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 06:56:58) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.0-53-generic-x86_64-with-glibc2.35', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "text = [t.split() for t,p in train]\n",
    "\n",
    "# the following configuration is the default configuration\n",
    "w2v = gensim.models.word2vec.Word2Vec(sentences=text,\n",
    "                                vector_size=100, window=5,               ### here we train a cbow model \n",
    "                                min_count=5,                      \n",
    "                                sample=0.001, workers=3,\n",
    "                                sg=1, hs=0, negative=5,        ### set sg to 1 to train a sg model\n",
    "                                cbow_mean=1, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 16:34:14,272 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'W2v-movies.dat', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-11-30T16:34:14.272230', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  5 2022, 06:56:58) \\n[GCC 7.5.0]', 'platform': 'Linux-5.15.0-53-generic-x86_64-with-glibc2.35', 'event': 'saving'}\n",
      "2022-11-30 16:34:14,275 : INFO : not storing attribute cum_table\n",
      "2022-11-30 16:34:14,427 : INFO : saved W2v-movies.dat\n"
     ]
    }
   ],
   "source": [
    "# Worth it to save the previous embedding\n",
    "w2v.save(\"W2v-movies.dat\")\n",
    "\n",
    "# You will be able to reload them:\n",
    "# w2v = gensim.models.Word2Vec.load(\"W2v-movies.dat\")\n",
    "# and you can continue the learning process if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained embeddings:\n",
    "\n",
    "<span style=\"color:red\"> FOR LATER </span>\n",
    "\n",
    "1. Test the learnt embedding from above\n",
    "2. Come back at this point and switch to pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 10:42:45,701 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2022-11-16 10:42:45,702 : INFO : built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\n",
      "2022-11-16 10:42:45,702 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\", 'datetime': '2022-11-16T10:42:45.702854', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n",
      "2022-11-16 10:42:45,761 : INFO : loading projection weights from /Users/vguigue/opt/anaconda3/lib/python3.9/site-packages/gensim/test/test_data/word2vec_pre_kv_c\n",
      "2022-11-16 10:42:45,778 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (1750, 10) matrix of type float32 from /Users/vguigue/opt/anaconda3/lib/python3.9/site-packages/gensim/test/test_data/word2vec_pre_kv_c', 'binary': False, 'encoding': 'utf8', 'datetime': '2022-11-16T10:42:45.778315', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "# # It's for later\n",
    "# 1. Test the learnt embedding from above\n",
    "# 2. Come back at this point and switch to pre-trained embeddings\n",
    "\n",
    "\n",
    "# from gensim.models import KeyedVectors\n",
    "# from gensim.test.utils import datapath\n",
    "# w2v = KeyedVectors.load_word2vec_format(datapath('word2vec_pre_kv_c'), binary=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Gensim, embeddings are loaded and can be used via the [\"KeyedVectors\"](https://radimrehurek.com/gensim/models/keyedvectors.html) class\n",
    "\n",
    "> Since trained word vectors are independent from the way they were trained (Word2Vec, FastText, WordRank, VarEmbed etc), they can be represented by a standalone structure, as implemented in this module.\n",
    "\n",
    ">The structure is called “KeyedVectors” and is essentially a mapping between entities and vectors. Each entity is identified by its string id, so this is a mapping between {str => 1D numpy array}.\n",
    "\n",
    ">The entity typically corresponds to a word (so the mapping maps words to 1D vectors), but for some models, they key can also correspond to a document, a graph node etc. To generalize over different use-cases, this module calls the keys entities. Each entity is always represented by its string id, no matter whether the entity is a word, a document or a graph node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Test learnt embeddings\n",
    "\n",
    "The word embedding space directly encodes similarities between words: the vector coding for the word \"great\" will be closer to the vector coding for \"good\" than to the one coding for \"bad\". Generally, [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) is the distance used when considering distance between vectors.\n",
    "\n",
    "KeyedVectors have a built in [similarity](https://radimrehurek.com/gensim/models /keyedvectors.html#gensim.models.keyedvectors.BaseKeyedVectors.similarity) method to compute the cosine similarity between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great and good: 1.0\n",
      "great and bad: 0.7906509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.18555216,  0.28182802, -0.05735041, -0.07272255, -0.22761118,\n",
       "       -0.25262886, -0.12532172,  0.4488599 , -0.56757474, -0.6151462 ,\n",
       "        0.46685237, -0.09261084, -0.12176673,  0.2639004 ,  0.25612387,\n",
       "        0.28722137,  0.0081128 , -0.25418323, -0.57590544, -0.52177286,\n",
       "        0.0394594 ,  0.18263415,  0.16050874, -0.47925568,  0.2878962 ,\n",
       "       -0.13675426, -0.22898513,  0.03787633, -0.34196448, -0.04853608,\n",
       "        0.05516415,  0.0805138 ,  0.42941424, -0.00677625, -0.06764948,\n",
       "        0.58166254,  0.19113442,  0.04576999, -0.26687568, -0.23444025,\n",
       "        0.25759748, -0.16480914,  0.1807987 ,  0.48934406,  0.04017064,\n",
       "        0.05247667, -0.05567148, -0.2775686 ,  0.34988064, -0.00962543,\n",
       "       -0.16213511, -0.24846335,  0.01001199,  0.23963335, -0.01478904,\n",
       "        0.10168232, -0.00201228, -0.11029024,  0.01138252, -0.3340219 ,\n",
       "        0.23361287,  0.21339937,  0.0207793 , -0.46637368, -0.63337606,\n",
       "        0.24431498, -0.03257083, -0.10490397, -0.14979857, -0.0759891 ,\n",
       "        0.14544757,  0.4894876 ,  0.6972538 ,  0.08731104,  0.14596032,\n",
       "       -0.45961642, -0.05849174,  0.11607827,  0.34264004, -0.03264562,\n",
       "       -0.13246521,  0.2567439 , -0.06453243,  0.54348385,  0.09516073,\n",
       "       -0.41973698,  0.27762944,  0.1478288 , -0.07210603, -0.05299513,\n",
       "        0.52047247,  0.12269678, -0.33521864, -0.44218716,  0.6718495 ,\n",
       "        0.29627597,  0.38357908, -0.77440304,  0.05073632, -0.01057062],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is great really closer to good than to bad ?\n",
    "print(\"great and good:\",w2v.wv.similarity(\"great\",\"great\"))\n",
    "print(\"great and bad:\",w2v.wv.similarity(\"great\",\"fantastic\"))\n",
    "w2v.wv.get_vector(\"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since cosine distance encodes similarity, neighboring words are supposed to be similar. The [most_similar](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.BaseKeyedVectors.most_similar) method returns the `topn` words given a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amazing', 0.785902202129364),\n",
       " ('incredible', 0.7500136494636536),\n",
       " ('excellent', 0.7368746995925903),\n",
       " ('fantastic', 0.7236931324005127),\n",
       " ('exceptional', 0.7027348279953003)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The query can be as simple as a word, such as \"movie\"\n",
    "\n",
    "# Try changing the word\n",
    "w2v.wv.most_similar(\"movie\",topn=5) # 5 most similar words\n",
    "w2v.wv.most_similar(\"awesome\",topn=5)\n",
    "#w2v.wv.most_similar(\"actor\",topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it can be a more complicated query\n",
    "Word embedding spaces tend to encode much more.\n",
    "\n",
    "The most famous exemple is: `vec(king) - vec(man) + vec(woman) => vec(queen)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actress', 0.8380442261695862),\n",
       " ('actress,', 0.7513940930366516),\n",
       " ('actress.', 0.6817273497581482)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is awesome - good + bad ?\n",
    "w2v.wv.most_similar(positive=[\"awesome\",\"bad\"],negative=[\"good\"],topn=3)  \n",
    "\n",
    "w2v.wv.most_similar(positive=[\"actor\",\"woman\"],negative=[\"man\"],topn=3) # do the famous exemple works for actor ?\n",
    "\n",
    "\n",
    "# Try other things like plurals for exemple.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test learnt \"synctactic\" and \"semantic\" similarities, Mikolov et al. introduced a special dataset containing a wide variety of three way similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 16:48:05,883 : INFO : Evaluating word analogies for top 300000 words in the model on ressources/questions-words.txt\n",
      "2022-11-30 16:48:06,535 : INFO : capital-common-countries: 0.0% (0/156)\n",
      "2022-11-30 16:48:07,052 : INFO : capital-world: 0.0% (0/111)\n",
      "2022-11-30 16:48:07,137 : INFO : currency: 0.0% (0/18)\n",
      "2022-11-30 16:48:08,389 : INFO : city-in-state: 0.0% (0/301)\n",
      "2022-11-30 16:48:10,092 : INFO : family: 33.3% (140/420)\n",
      "2022-11-30 16:48:13,495 : INFO : gram1-adjective-to-adverb: 1.6% (14/870)\n",
      "2022-11-30 16:48:15,577 : INFO : gram2-opposite: 3.4% (19/552)\n",
      "2022-11-30 16:48:20,270 : INFO : gram3-comparative: 16.8% (200/1190)\n",
      "2022-11-30 16:48:23,424 : INFO : gram4-superlative: 8.5% (64/756)\n",
      "2022-11-30 16:48:26,799 : INFO : gram5-present-participle: 18.3% (149/812)\n",
      "2022-11-30 16:48:30,748 : INFO : gram6-nationality-adjective: 1.4% (14/967)\n",
      "2022-11-30 16:48:35,679 : INFO : gram7-past-tense: 20.8% (262/1260)\n",
      "2022-11-30 16:48:38,968 : INFO : gram8-plural: 6.9% (56/812)\n",
      "2022-11-30 16:48:41,496 : INFO : gram9-plural-verbs: 30.6% (199/650)\n",
      "2022-11-30 16:48:41,498 : INFO : Quadruplets with out-of-vocabulary words: 54.6%\n",
      "2022-11-30 16:48:41,499 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2022-11-30 16:48:41,500 : INFO : Total accuracy: 12.6% (1117/8875)\n"
     ]
    }
   ],
   "source": [
    "out = w2v.wv.evaluate_word_analogies(\"ressources/questions-words.txt\",case_insensitive=True)  #original semantic syntactic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training the w2v models on the review dataset, since it hasn't been learnt with a lot of data, it does not perform very well. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3:  sentiment classification\n",
    "\n",
    "In the previous practical session, we used a bag of word approach to transform text into vectors.\n",
    "Here, we propose to try to use word vectors (previously learnt or loaded).\n",
    "\n",
    "\n",
    "### <font color='green'> Since we have only word vectors and that sentences are made of multiple words, we need to aggregate them. </font>\n",
    "\n",
    "\n",
    "### (1) Vectorize reviews using word vectors:\n",
    "\n",
    "Word aggregation can be done in different ways:\n",
    "\n",
    "- Sum\n",
    "- Average\n",
    "- Min/feature\n",
    "- Max/feature\n",
    "\n",
    "#### a few pointers:\n",
    "\n",
    "- `w2v.wv.vocab` is a `set()` of the vocabulary (all existing words in your model)\n",
    "- `np.minimum(a,b) and np.maximum(a,b)` respectively return element-wise min/max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04125731  0.20379713  0.03768607  0.00516557 -0.00841729 -0.27480258\n",
      "  0.14400779  0.36917644 -0.28746756 -0.27401469 -0.07440121 -0.32779558\n",
      " -0.08314698  0.16957724  0.0666801  -0.12828014  0.1318984  -0.17255477\n",
      " -0.08795797 -0.51685997  0.20756688  0.01901542  0.14567812 -0.14867894\n",
      "  0.10895896  0.02771798 -0.24277087 -0.10604663 -0.14230662  0.16944706\n",
      "  0.27908388 -0.09383054  0.12281318 -0.27108224 -0.09827425  0.24237853\n",
      " -0.00441102  0.06457499 -0.10407426 -0.23289047  0.16032953 -0.07839969\n",
      " -0.06473605  0.049773    0.18888303 -0.07208321 -0.14654011 -0.08383994\n",
      "  0.2169286   0.25135871  0.06710525 -0.1575354   0.11146252 -0.05014786\n",
      " -0.07329835  0.13752648  0.21171506  0.05712509 -0.07432949 -0.01637495\n",
      "  0.08734892 -0.04477437  0.22452784  0.13222959 -0.14718056  0.15705366\n",
      " -0.03281259  0.11752325 -0.23630766  0.03881441  0.00681997  0.08456758\n",
      "  0.20613663  0.07743888  0.09836341 -0.02380281  0.16093135 -0.08806462\n",
      " -0.09148719 -0.04534538 -0.10460684 -0.01353595 -0.17645269  0.22534523\n",
      "  0.04257927 -0.09355052  0.11833751  0.07673998  0.29572883  0.10039618\n",
      "  0.31942203  0.06296316 -0.06515822 -0.06500303  0.31783739 -0.06388587\n",
      "  0.01214672 -0.27994109 -0.05330994 -0.01809784]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# We first need to vectorize text:\n",
    "# First we propose to a sum of them\n",
    "\n",
    "\"\"\"\n",
    "This function should vectorize one review\n",
    "input: str\n",
    "output: np.array(float)\n",
    "\"\"\"    \n",
    "def vectorize(text,mean=False):\n",
    "    vec = np.zeros(100)\n",
    "    cpt = 0 \n",
    "    for word in text.split():\n",
    "        if word in w2v.wv :\n",
    "            vec = vec + w2v.wv[word]\n",
    "            cpt += 1 \n",
    "    vec = vec / cpt\n",
    "    return vec\n",
    "    \n",
    "\n",
    "classes = [pol for text,pol in train]\n",
    "X = [vectorize(text) for text,pol in train]\n",
    "X_test = [vectorize(text) for text,pol in test]\n",
    "true = [pol for text,pol in test]\n",
    "\n",
    "#let's see what a review vector looks like.\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The undoubted highlight of this movie is Peter O'Toole's performance. In turn wildly comical and terribly terribly tragic. Does anybody do it better than O'Toole? I don't think so. What a great face that man has!<br /><br />The story is an odd one and quite disturbing and emotionally intense in parts (especially toward the end) but it is also oddly touching and does succeed on many levels. However, I felt the film basically revolved around Peter O'Toole's luminous performance and I'm sure I wouldn't have enjoyed it even half as much if he hadn't been in it.\", 1]\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(train[0])\n",
    "print(classes)\n",
    "#print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Train a classifier \n",
    "as in the previous practical session, train a logistic regression to do sentiment classification with word vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8184\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scikit Logistic Regression\n",
    "\n",
    "mod = LogisticRegression()\n",
    "mod.fit(X,classes)\n",
    "#mod.score(X_test,true)\n",
    "yhat = mod.predict(X_test)\n",
    "print(accuracy_score(yhat,true))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "performance should be worst than with bag of word (~80%). Sum/Mean aggregation does not work well on long reviews (especially with many frequent words). This adds a lot of noise.\n",
    "\n",
    "## **Todo** :  Try answering the following questions:\n",
    "\n",
    "- Which word2vec model works best: skip-gram or cbow\n",
    "- Do pretrained vectors work best than those learnt on the train dataset ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**(Bonus)** To have a better accuracy, we could try two things:\n",
    "- Better aggregation methods (weight by tf-idf ?)\n",
    "- Another word vectorizing method such as [fasttext](https://radimrehurek.com/gensim/models/fasttext.html)\n",
    "- A document vectorizing method such as [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Generate text with a recurrent neural network (Pytorch) ---\n",
    "### (Mostly Read & Run)\n",
    "\n",
    "The goal is to replicate the (famous) experiment from [Karpathy's blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "\n",
    "To learn to generate text, we train a recurrent neural network to do the following task:\n",
    "\n",
    "Given a \"chunk\" of text: `this is random text`\n",
    "\n",
    "the goal of the network is to predict each character in **`his is random text` ** sequentially given the following sequential input **`this is random tex`**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input ->  Output\n",
    "--------------\n",
    "T    ->    H\n",
    "H    ->    I\n",
    "I    ->    S\n",
    "S    ->    \" \"\n",
    "\" \"  ->    I\n",
    "I    ->    S\n",
    "S    ->    \" \"\n",
    "[...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load text (dataset/input.txt)\n",
    "\n",
    "Before building training batch, we load the full text in RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/input.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hippo/Bureau/IODAA/AGRO/ONTO_TAL/tuto_TAL/notebooks/3-representationLearning.ipynb Cellule 30\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hippo/Bureau/IODAA/AGRO/ONTO_TAL/tuto_TAL/notebooks/3-representationLearning.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m all_characters \u001b[39m=\u001b[39m string\u001b[39m.\u001b[39mprintable\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hippo/Bureau/IODAA/AGRO/ONTO_TAL/tuto_TAL/notebooks/3-representationLearning.ipynb#X40sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m n_characters \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(all_characters)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hippo/Bureau/IODAA/AGRO/ONTO_TAL/tuto_TAL/notebooks/3-representationLearning.ipynb#X40sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m file \u001b[39m=\u001b[39m unidecode\u001b[39m.\u001b[39munidecode(\u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mdataset/input.txt\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mread()) \u001b[39m#clean text => only ascii\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hippo/Bureau/IODAA/AGRO/ONTO_TAL/tuto_TAL/notebooks/3-representationLearning.ipynb#X40sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m file_len \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(file)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hippo/Bureau/IODAA/AGRO/ONTO_TAL/tuto_TAL/notebooks/3-representationLearning.ipynb#X40sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mfile_len =\u001b[39m\u001b[39m'\u001b[39m, file_len)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/input.txt'"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "file = unidecode.unidecode(open('dataset/input.txt').read()) #clean text => only ascii\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Helper functions:\n",
    "\n",
    "We have a text and we want to feed batch of chunks to a neural network:\n",
    "\n",
    "one chunk  A,B,C,D,E\n",
    "[input] A,B,C,D -> B,C,D,E [output]\n",
    "\n",
    "Note: we will use an embedding layer instead of a one-hot encoding scheme.\n",
    "\n",
    "for this, we have 3 functions:\n",
    "\n",
    "- One to get a random str chunk of size `chunk_len` : `random_chunk` \n",
    "- One to turn a chunk into a tensor of size `(1,chunk_len)` coding for each characters : `char_tensor`\n",
    "- One to return random input and output chunks of size `(batch_size,chunk_len)` : `random_training_set`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "\n",
    "#Get a piece of text\n",
    "def random_chunk(chunk_len):\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "\n",
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(1,len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[0,c] = all_characters.index(string[c])\n",
    "    return tensor\n",
    "\n",
    "\n",
    "#Turn a piece of text in train/test\n",
    "def random_training_set(chunk_len=200, batch_size=8):\n",
    "    chunks = [random_chunk(chunk_len) for _ in range(batch_size)]\n",
    "    inp = torch.cat([char_tensor(chunk[:-1]) for chunk in chunks],dim=0)\n",
    "    target = torch.cat([char_tensor(chunk[1:]) for chunk in chunks],dim=0)\n",
    "    \n",
    "    return inp, target\n",
    "\n",
    "print(random_training_set(10,4))  ## should return 8 chunks of 10 letters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual RNN model (only thing to complete):\n",
    "\n",
    "It should be composed of three distinct modules:\n",
    "\n",
    "- an [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) (n_characters, hidden_size)\n",
    "\n",
    "```\n",
    "nn.Embedding(len_dic,size_vec)\n",
    "```\n",
    "- a [recurrent](https://pytorch.org/docs/stable/nn.html#recurrent-layers) layer (hidden_size, hidden_size)\n",
    "```\n",
    "nn.RNN(in_size,out_size) or nn.GRU() or nn.LSTM() => rnn_cell parameter\n",
    "```\n",
    "- a [prediction](https://pytorch.org/docs/stable/nn.html#linear) layer (hidden_size, output_size)\n",
    "\n",
    "```\n",
    "nn.Linear(in_size,out_size)\n",
    "```\n",
    "=> Complete the `init` function code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as f\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_char, hidden_size, output_size, n_layers=1,rnn_cell=nn.RNN):\n",
    "        \"\"\"\n",
    "        Create the network\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.n_char = n_char\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #  (batch,chunk_len) -> (batch, chunk_len, hidden_size)  \n",
    "        self.embed = ####\n",
    "        \n",
    "        # (batch, chunk_len, hidden_size)  -> (batch, chunk_len, hidden_size)  \n",
    "        self.rnn = ####\n",
    "        \n",
    "        #(batch, chunk_len, hidden_size) -> (batch, chunk_len, output_size)  \n",
    "        self.predict = ####\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        batched forward: input is (batch > 1,chunk_len)\n",
    "        \"\"\"\n",
    "        input = self.embed(input)\n",
    "        output,_  = self.rnn(input)\n",
    "        output = self.predict(f.tanh(output))\n",
    "        return output\n",
    "    \n",
    "    def forward_seq(self, input,hidden=None):\n",
    "        \"\"\"\n",
    "        not batched forward: input is  (1,chunk_len)\n",
    "        \"\"\"\n",
    "        input = self.embed(input)\n",
    "        output,hidden  = self.rnn(input.unsqueeze(0),hidden)\n",
    "        output = self.predict(f.tanh(output))\n",
    "        return output,hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Text generation function\n",
    "\n",
    "Sample text from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(model,prime_str='A', predict_len=100, temperature=0.8):\n",
    "    prime_input = char_tensor(prime_str).squeeze(0)\n",
    "    hidden = None\n",
    "    predicted = prime_str+\"\"\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "\n",
    "    for p in range(len(prime_str)-1):\n",
    "        _,hidden = model.forward_seq(prime_input[p].unsqueeze(0),hidden)\n",
    "            \n",
    "    #print(hidden.size())\n",
    "    for p in range(predict_len):\n",
    "        output, hidden = model.forward_seq(prime_input[-1].unsqueeze(0), hidden)\n",
    "                # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        #print(output_dist)\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        #print(top_i)\n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        prime_input = torch.cat([prime_input,char_tensor(predicted_char).squeeze(0)])\n",
    "\n",
    "    return predicted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training loop for net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "###Parameters\n",
    "n_epochs = 20000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100\n",
    "n_layers = 5\n",
    "lr = 0.005\n",
    "batch_size = 16\n",
    "chunk_len = 80\n",
    "\n",
    "####\n",
    "\n",
    "model = RNN(n_characters, hidden_size, n_characters, n_layers) #create model\n",
    "model_optimizer = torch.optim.Adam(model.parameters(), lr=lr) #create Adam optimizer\n",
    "criterion = nn.CrossEntropyLoss() #chose criterion\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "\n",
    "def train(inp, target):\n",
    "    \"\"\"\n",
    "    Train sequence for one chunk:\n",
    "    \"\"\"\n",
    "    #reset gradients\n",
    "    model_optimizer.zero_grad() \n",
    "    \n",
    "    # predict output\n",
    "    output = model(inp)\n",
    "    \n",
    "    #compute loss\n",
    "    loss =  criterion(output.view(batch_size*chunk_len,-1), target.view(-1)) \n",
    "\n",
    "    #compute gradients and backpropagate\n",
    "    loss.backward() \n",
    "    model_optimizer.step() \n",
    "\n",
    "    return loss.data.item() \n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set(chunk_len,batch_size))  #train on one chunk \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(generate(model,'Wh', 100), '\\n')\n",
    "       \n",
    "\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different temperatures\n",
    "\n",
    "Changing the distribution sharpness has an impact on character sampling:\n",
    "\n",
    "more or less probable things are sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(generate(model,'T', 200, temperature=1))\n",
    "print(\"----\")\n",
    "print(generate(model,'Th', 200, temperature=0.8))\n",
    "print(\"----\")\n",
    "\n",
    "print(generate(model,'Th', 200, temperature=0.5))\n",
    "print(\"----\")\n",
    "\n",
    "print(generate(model,'Th', 200, temperature=0.3))\n",
    "print(\"----\")\n",
    "\n",
    "print(generate(model,'Th', 200, temperature=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving this code:\n",
    "\n",
    "(a) Tinker with parameters:\n",
    "\n",
    "- Is it really necessary to have 100 dims character embeddings\n",
    "- Chunk length can be gradually increased\n",
    "- Try changing RNN cell type (GRUs - LSTMs)\n",
    "\n",
    "(b) Add GPU support to go faster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------ End of practical\n",
    "\n",
    "#### Legacy loading code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from os.path import split as pathsplit\n",
    "\n",
    "dir_train = \"dataset/aclImdb/train/\"\n",
    "dir_test = \"dataset/aclImdb/test/\"\n",
    "\n",
    "train_files = glob.glob(dir_train+'pos/*.txt') + glob.glob(dir_train+'neg/*.txt')\n",
    "test_files = glob.glob(dir_test+'pos/*.txt') + glob.glob(dir_test+'neg/*.txt')\n",
    "\n",
    "\n",
    "def get_polarity(f):\n",
    "    \"\"\"\n",
    "    Extracts polarity from filename:\n",
    "    0 is negative (< 5)\n",
    "    1 is positive (> 5)\n",
    "    \"\"\"\n",
    "    _,name = pathsplit(f)\n",
    "    if int(name.split('_')[1].split('.')[0]) < 5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def open_one(f):\n",
    "    \n",
    "    polarity = get_polarity(f)\n",
    "    \n",
    "    with open(f,\"r\") as review:\n",
    "        text = \" \".join(review.readlines()).strip()\n",
    "    \n",
    "    return (text,polarity)\n",
    "\n",
    "print(open_one(train_files[0]))\n",
    "\n",
    "train = [open_one(x) for x in train_files] #contains (text,pol) couples\n",
    "test = [open_one(x) for x in test_files]   #contains (text,pol) couples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "baacd7ded0742aa8408bda3ed6ced71320ba4869ece4e05e453d0cf31ed1376f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
